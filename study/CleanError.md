# ğŸ“š æ‰“å¡æ•°æ®æ¸…æ´—ã€Œé—®é¢˜å‘ç”Ÿ â†’ é€æ­¥è§£å†³ã€çŸ¥è¯†åº“  

---

## ğŸ§­ æ—¶é—´çº¿ & é€æ­¥å¤ç›˜

| æ—¶é—´ | ç°è±¡/æŠ¥é”™ | å…³é”®åŠ¨ä½œ | æ ¹å› å®šä½ | ä¿®å¤æ–¹æ¡ˆ |
|---|---|---|---|---|
| **T0** | è¿è¡Œåæ‹¿åˆ° `Empty DataFrame` | æ‰“å° `len(df)` å‘ç° 0 è¡Œ | æ•°æ®åœ¨æŸä¸€æ­¥è¢«å…¨éƒ¨è¿‡æ»¤ | åœ¨ `clean()` æ’å…¥ 4 ä¸ª `print("ã€æ­¥éª¤ã€‘è¡Œæ•°:", len(df))` |
| **T1** | ã€å»æ—¥æœŸç©ºå€¼åã€‘è¡Œæ•° = 0 | æ‰“å° `df_raw.columns` ä¸ `df_raw.iloc[0]` | åˆ—åæ­£ç¡®ï¼Œä½†æ•´åˆ—æ—¥æœŸä¸º `NaT` | å‘ç° `_normalize_date` äºŒæ¬¡ `to_datetime` + é”™è¯¯ `origin` |
| **T2** | `_normalize_date` è¿”å›å…¨ `NaT` | æ‰“å° `df_raw[date_col].head()` | æºæ•°æ®å·²æ˜¯ `"2025-08-01 00:00:00"` å­—ç¬¦ä¸² | å»æ‰ `origin`ï¼Œåª `.normalize()` |
| **T3** | æ—¶é—´åˆ—å‡ºç° `1900-01-01 20:42:00` | æŸ¥çœ‹ `_normalize_time` è¿”å›ç±»å‹ | `pd.to_datetime` è‡ªåŠ¨è¡¥æ—¥æœŸ 1900-01-01 | æ”¹ä¸ºè¿”å› `"HH:MM"` å­—ç¬¦ä¸² |
| **T4** | æ’åº/å»é‡é€»è¾‘å¤±æ•ˆ | æ£€æŸ¥ `df["end_ord"]` ç±»å‹ | å­—ç¬¦ä¸²æ— æ³•ç›´æ¥æ’åº | æ’åºå‰ä¸´æ—¶ `pd.to_datetime(time_str, format="%H:%M")` |
| **T5** | æ‹…å¿ƒå¼‚å¸¸ä¸­æ–­ | è¯¢é—® | æœªåŠ å¼‚å¸¸æ•è· | å¤–å±‚åŒ… `safe_clean()`ï¼Œå†™ `log/clean_error.log` |

---

## ğŸ” æ ‡å‡†åŒ–æ’æŸ¥ 5 æ­¥æ³•ï¼ˆ30 ç§’å®šä½ï¼‰

1. **è¯»æ–‡ä»¶**  
   ```python
   df_raw = pd.read_excel(file, dtype=str)
   print("åŸå§‹è¡Œæ•°:", len(df_raw))
   print("åˆ—å:", list(df_raw.columns))
çœ‹é¦–è¡Œ
Python
å¤åˆ¶
print("é¦–è¡ŒåŸå§‹å€¼ï¼š", df_raw.iloc[0].to_dict())
çœ‹è„å€¼
Python
å¤åˆ¶
print("æ—¥æœŸåˆ—å‰5è¡Œï¼š\n", df_raw["æ—¥æœŸ"].head())
çœ‹ç±»å‹
Python
å¤åˆ¶
print("æ¸…æ´—å dtypesï¼š\n", df.dtypes)
çœ‹ç©ºå€¼
Python
å¤åˆ¶
print("ç©ºå€¼ç»Ÿè®¡ï¼š\n", df.isna().sum())
ğŸ› ï¸ å¯å¤ç”¨æœ€å°å‡½æ•°åº“
Python
å¤åˆ¶
# 1. é€šç”¨è¯»å–
```def load_any(path: str) -> pd.DataFrame:
    if path.lower().endswith(".xlsx"):
        return pd.read_excel(path, dtype=str)
    enc = chardet.detect(open(path, "rb").read(100_000))["encoding"] or "utf-8"
    return pd.read_csv(path, dtype=str, encoding=enc)
```

# 2. æ—¥æœŸæ¸…æ´—ï¼ˆä¿ç•™æ—¥æœŸ 00:00:00ï¼‰
```def norm_date(x):
    return pd.to_datetime(x, errors="coerce").normalize()
```
# 3. æ—¶é—´æ¸…æ´—ï¼ˆHH:MM å­—ç¬¦ä¸²ï¼‰
```def norm_time(x):
    ts = pd.to_datetime(x, errors="coerce")
    return ts.strftime("%H:%M") if pd.notna(ts) else None
```
# 4. æ’åºå»é‡ï¼ˆæ—¶é—´åˆ—æ˜¯å­—ç¬¦ä¸²æ—¶ï¼‰
```def dedup_day_latest(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["end_ord"]  = pd.to_datetime(df["actual_end"],   format="%H:%M")
    df["start_ord"] = pd.to_datetime(df["actual_start"], format="%H:%M")
    return (df.sort_values(["date", "end_ord", "start_ord"])
              .drop_duplicates(subset=["date"], keep="last")
              .drop(columns=["end_ord", "start_ord"]))
```
âœ… ä¸Šçº¿å‰ 10 ç§’ Checklist
[ ] æ‰“å° len(df_raw) ä¸åˆ—å  

[ ] æ‰“å°é¦–è¡ŒåŸå§‹å€¼ç¡®è®¤åˆ—å  

[ ] æ—¥æœŸåˆ— â†’ datetime64[ns]  

[ ] æ—¶é—´åˆ— â†’ "HH:MM" å­—ç¬¦ä¸²  

[ ] æ’åº/å»é‡å‰ç”¨ format="%H:%M" è½¬ä¸´æ—¶ datetime64  

[ ] ç©ºå€¼æ—¥å¿—æ–‡ä»¶æ­£å¸¸ç”Ÿæˆ

[ ] å¤–å±‚ safe_clean() æ•è·å¼‚å¸¸

ğŸ“Œ ä¸€å¥è¯å£è¯€
â€œå…ˆæ•°è¡Œï¼Œå†çœ‹åˆ—ï¼Œä¸‰çœ‹è„å€¼ï¼Œå››çœ‹ç±»å‹ï¼Œäº”çœ‹ç©ºå€¼ï¼Œ30 ç§’å®šä½ 99% é—®é¢˜ã€‚â€